{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "inOrkHvMlXS_"
      },
      "source": [
        "# Sentiment140: Predicting Stock Movement Using Sentiment Analysis of Twitter Feed with Neural Networks\n",
        "\n",
        "- baseline: https://www.scirp.org/journal/paperinformation.aspx?paperid=104142#ref9\n",
        "- sentiment kaggle: https://www.kaggle.com/datasets/kazanova/sentiment140 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2wOKRlh30DI"
      },
      "source": [
        "# Sentiment 140 Data\n",
        "For the training data, we are going to use a sentiment tagged Twitter dataset of 1.6 million tweets, collected from Sentiment140 for sentiment classification. The tweets are tagged ‘1’ and ‘0’ for being ‘positive’ and ‘negative’ respectively.\n",
        "\n",
        "It contains the following 6 fields:\n",
        "\n",
        "1. **target**: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
        "\n",
        "2. **ids**: The id of the tweet ( 2087)\n",
        "\n",
        "3. **date**: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
        "\n",
        "4. **flag**: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
        "\n",
        "5. **user**: the user that tweeted (robotickilldozr)\n",
        "\n",
        "6. **text**: the text of the tweet (Lyx is cool)\n",
        "\n",
        "Citation: Go, A., Bhayani, R. and Huang, L., 2009. Twitter sentiment classification using distant supervision. CS224N Project Report, Stanford, 1(2009), p.12."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMSnqBKp5Fm5"
      },
      "source": [
        "### Download the data\n",
        "Download from the Kaggle website and then save to your local directory. \n",
        "\n",
        "Kaggle: https://www.kaggle.com/datasets/kazanova/sentiment140\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xapVlOt2XyxO"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "RURsX5hXDP_h"
      },
      "outputs": [],
      "source": [
        "# utilities\n",
        "import string \n",
        "import re \n",
        "import pickle # not used\n",
        "import pandas as pd \n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "MJ9rLm57lSw1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /Users/Dell/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /Users/Dell/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /Users/Dell/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# nltk\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt') \n",
        "nltk.download('wordnet') \n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "id": "jqY_OlIsPbJN"
      },
      "outputs": [],
      "source": [
        "# sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2A4rqssgPAa"
      },
      "source": [
        "### Load in data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfpHqvto5Ofo"
      },
      "outputs": [],
      "source": [
        "# import drive so you can access your folders\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "rw5FWRfFgJPK"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>time</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811372</td>\n",
              "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>joy_wolf</td>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment    tweet_id                          time      flag  \\\n",
              "0          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
              "1          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
              "2          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "3          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
              "4          0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
              "\n",
              "            user                                              tweet  \n",
              "0  scotthamilton  is upset that he can't update his Facebook by ...  \n",
              "1       mattycus  @Kenichan I dived many times for the ball. Man...  \n",
              "2        ElleCTF    my whole body feels itchy and like its on fire   \n",
              "3         Karoli  @nationwideclass no, it's not behaving at all....  \n",
              "4       joy_wolf                      @Kwesidei not the whole crew   "
            ]
          },
          "execution_count": 238,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# read in data\n",
        "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin')\n",
        "\n",
        "# add in the column names\n",
        "df.columns = ['sentiment', 'tweet_id', 'time', 'flag', 'user', 'tweet']\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "9ei00dwFhVcK"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  sentiment\n",
              "0  is upset that he can't update his Facebook by ...          0\n",
              "1  @Kenichan I dived many times for the ball. Man...          0\n",
              "2    my whole body feels itchy and like its on fire           0\n",
              "3  @nationwideclass no, it's not behaving at all....          0\n",
              "4                      @Kwesidei not the whole crew           0"
            ]
          },
          "execution_count": 239,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a new dataframe with only tweets and sentiment\n",
        "features ='tweet'\n",
        "target = 'sentiment'\n",
        "\n",
        "df = df[[features, target]]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mH4792XTh8L6"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "1uo80AS8h_ji"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599999 entries, 0 to 1599998\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count    Dtype \n",
            "---  ------     --------------    ----- \n",
            " 0   tweet      1599999 non-null  object\n",
            " 1   sentiment  1599999 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 24.4+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "vNUHua2EiVmA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599999 entries, 0 to 1599998\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count    Dtype \n",
            "---  ------     --------------    ----- \n",
            " 0   tweet      1599999 non-null  object\n",
            " 1   sentiment  1599999 non-null  int8  \n",
            "dtypes: int8(1), object(1)\n",
            "memory usage: 13.7+ MB\n"
          ]
        }
      ],
      "source": [
        "# downcast to smaller integer size to reduce memory: int64 -> int8\n",
        "df['sentiment'] = pd.to_numeric(df['sentiment'], downcast='integer')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "CLfR5-7SiyUU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 4], dtype=int8)"
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find all sentiment values in the dataset \n",
        "df.sentiment.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "cZ5xUMuOi5w6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    800000\n",
              "0    799999\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "execution_count": 243,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# change 4 to 1 (positive)\n",
        "df['sentiment'] = df['sentiment'].replace(4, 1)\n",
        "df['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "xRM9gYcYC2tw"
      },
      "outputs": [],
      "source": [
        "class TweetCleaner:\n",
        "  def __init__(self):\n",
        "    self.stop_words = set(stopwords.words('english'))\n",
        "    self.emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':(': 'sad', 'XD': 'laughing',\n",
        "          ':-(': 'sad', ':-<': 'sad', ':P': 'stuck-out-tongue', ':O': 'surprised',\n",
        "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed', \n",
        "          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
        "          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
        "          ':/': 'confused', ':|': 'neutral-face', \":'-)\": 'sadsmile', \"<3\": 'love',\n",
        "          \":'-)\": 'tears-of-happiness'}\n",
        "\n",
        "  def lowercase(self, tweet):\n",
        "    ''' Each text is converted to lowercase. '''\n",
        "    return tweet.lower()\n",
        "  \n",
        "  def replace_url(self, tweet):\n",
        "    ''' Links starting with “Http” or “https” or “www” are replaced by “URL” '''\n",
        "    url_regex = re.compile(r'(http[s]?://|www\\.)\\S+')\n",
        "    return url_regex.sub('URL', tweet)\n",
        "\n",
        "  def replace_emojis(self, tweet):\n",
        "    '''Replace emojis by using a pre-defined dictionary containing emojis \n",
        "      along with their meaning. (e.g.: “:)” to “EMOJIsmile”) '''\n",
        "    for emoji in self.emojis.keys():\n",
        "      tweet = tweet.replace(emoji, \"EMOJI\" + self.emojis[emoji]) \n",
        "    return tweet\n",
        "\n",
        "  def replace_username(self, tweet):\n",
        "    ''' Replace @Usernames with the word “USER”. (e.g.: “@Kaggle” to “USER”)'''\n",
        "    user_regex = re.compile(r'@[^\\s]+')\n",
        "    return user_regex.sub('USER', tweet)  \n",
        "\n",
        "  def remove_nonalpha(self, tweet):\n",
        "    ''' Replacing characters except Digits and Alphabets with space.'''\n",
        "    nonalpha_regex = re.compile(r'[^a-zA-Z0-9]')\n",
        "    return nonalpha_regex.sub(\" \", tweet)\n",
        "  \n",
        "  def remove_consecutives(self, tweet):\n",
        "    ''' 3 or more consecutive letters are \n",
        "        replaced by two letters. (e.g.: “Heyyyy” to “Heyy”) '''\n",
        "    sequencePattern   = r\"(.)\\1\\1+\"\n",
        "    seqReplacePattern = r\"\\1\\1\"\n",
        "    return re.sub(sequencePattern, seqReplacePattern, tweet)\n",
        "\n",
        "  def remove_stop_short_words(self, tweet):\n",
        "    ''' English words that do not add much meaning to a sentence are removed\n",
        "        and Words with a length of less than two are eliminated.'''\n",
        "    words = nltk.word_tokenize(tweet)\n",
        "    words = [word for word in words if word not in self.stop_words and len(word) >= 2]\n",
        "    return ' '.join(words)\n",
        "\n",
        "  def lemmatize(self, tweet):\n",
        "    ''' Converting word to its base form. '''\n",
        "    tweetwords = ''\n",
        "    for word in tweet.split():\n",
        "      word = WordNetLemmatizer().lemmatize(word)\n",
        "      tweetwords += (word+' ')\n",
        "    return tweetwords\n",
        "\n",
        "  def clean_onetweet(self, tweet):\n",
        "    ''' cleans one single tweet '''\n",
        "    cleaned = self.lowercase(tweet)\n",
        "    cleaned = self.replace_url(cleaned)\n",
        "    cleaned = self.replace_emojis(cleaned)\n",
        "    cleaned = self.replace_username(cleaned)\n",
        "    cleaned = self.remove_nonalpha(cleaned)\n",
        "    cleaned = self.remove_consecutives(cleaned)\n",
        "    cleaned = self.remove_stop_short_words(cleaned)\n",
        "    cleaned = self.lemmatize(cleaned)\n",
        "    return cleaned\n",
        "\n",
        "  def clean_alltweets(self, df):\n",
        "    ''' cleans all tweets in the dataframe'''\n",
        "    df['tweets_processed'] = df['tweet'].apply(self.clean_onetweet)\n",
        "    df = df.drop(columns=['tweet'])\n",
        "    df = df.rename(columns={'tweets_processed': 'tweet'})\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "id": "aS2oUKEjEjlJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "USER dog money sitting URL baby foot \n"
          ]
        }
      ],
      "source": [
        "# testing one tweet\n",
        "tweet = \"@jane and her Dogs have g !$MONEY sitting with https://www.mlq.ai/ai-companies-trading-investing/ babies with feet\"\n",
        "tweetCleaner = TweetCleaner()\n",
        "\n",
        "print(tweetCleaner.clean_onetweet(tweet))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "metadata": {
        "id": "5elH-IxWV6ly"
      },
      "outputs": [],
      "source": [
        "# method for processing tweets\n",
        "def process_tweet_dataframe(df):\n",
        "  tweetCleaner = TweetCleaner()\n",
        "  \n",
        "  t = time.time()\n",
        "  df_processed = tweetCleaner.clean_alltweets(df)\n",
        "  print(f'Text Preprocessing complete.')\n",
        "  print(f'Time Taken: {round(time.time()-t)} seconds')\n",
        "  return df_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OEs1bvDX7LR"
      },
      "outputs": [],
      "source": [
        "df_processed = process_tweet_dataframe(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55h7Ju6SViZC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweets_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>0</td>\n",
              "      <td>upset update facebook texting might cry result...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "      <td>0</td>\n",
              "      <td>USER dived many time ball managed save 50 rest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>0</td>\n",
              "      <td>whole body feel itchy like fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "      <td>0</td>\n",
              "      <td>USER behaving mad see</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Kwesidei not the whole crew</td>\n",
              "      <td>0</td>\n",
              "      <td>USER whole crew</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  sentiment  \\\n",
              "0  is upset that he can't update his Facebook by ...          0   \n",
              "1  @Kenichan I dived many times for the ball. Man...          0   \n",
              "2    my whole body feels itchy and like its on fire           0   \n",
              "3  @nationwideclass no, it's not behaving at all....          0   \n",
              "4                      @Kwesidei not the whole crew           0   \n",
              "\n",
              "                                    tweets_processed  \n",
              "0  upset update facebook texting might cry result...  \n",
              "1  USER dived many time ball managed save 50 rest...  \n",
              "2                   whole body feel itchy like fire   \n",
              "3                             USER behaving mad see   \n",
              "4                                   USER whole crew   "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# view processed dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0_ezaElWYrw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>upset update facebook texting might cry result...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>USER dived many time ball managed save 50 rest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>whole body feel itchy like fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>USER behaving mad see</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>USER whole crew</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment                                              tweet\n",
              "0          0  upset update facebook texting might cry result...\n",
              "1          0  USER dived many time ball managed save 50 rest...\n",
              "2          0                   whole body feel itchy like fire \n",
              "3          0                             USER behaving mad see \n",
              "4          0                                   USER whole crew "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_processed.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvDBnlxZYzJp"
      },
      "source": [
        "### Save processed tweets to csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "metadata": {
        "id": "ebM-u2UuYxW0"
      },
      "outputs": [],
      "source": [
        "# save the DataFrame to a CSV file\n",
        "df_processed.to_csv('processed_sentiment140_tweets.csv', index=False)\n",
        "\n",
        "# Uncomment the below lines and comment previous lines for loading preprocessed df\n",
        "# df_processed = pd.read_csv('processed_sentiment140_tweets.csv')\n",
        "# df_processed.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLXDWAL94OPy"
      },
      "source": [
        "### Splitting data into train and test\n",
        "We perform a random split over\n",
        "the dataset to divide the dataset into a training dataset and a testing data set. The training dataset contains 1.52 million tweets, whereas the testing dataset contains 80,000 tweets.\n",
        "\n",
        "5 percent of the training data from the sentiment 140 dataset was used to test the trained models. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "metadata": {
        "id": "PWJOmxOyZu0o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1599538 entries, 0 to 1599998\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count    Dtype \n",
            "---  ------     --------------    ----- \n",
            " 0   sentiment  1599538 non-null  int64 \n",
            " 1   tweet      1599538 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 36.6+ MB\n"
          ]
        }
      ],
      "source": [
        "df_processed.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "4yZBmnJPmot5"
      },
      "outputs": [],
      "source": [
        "df = df_processed\n",
        "# Split dataset into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[\"tweet\"], df[\"sentiment\"], test_size=0.05, random_state=42)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vectorize the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "metadata": {},
      "outputs": [],
      "source": [
        "# vectorize the text data using TF-IDF\n",
        "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuQJQIp6mEdv"
      },
      "source": [
        "### Train the model on SVM\n",
        "\n",
        "The five models used to train were Logistic Regression (LR), Support Vector Machines (SVM), Decision Tree (DT), Boosted Tree (BT), and Random Forests (RF). The **best performance was SVM** (0.83 Accuracy, 0.83 F1 score, 0.83 Precision, 0.83 Recall).\n",
        "\n",
        "The text data is vectorized using TF-IDF (term frequency-inverse document frequency) using the TfidfVectorizer class from scikit-learn. This converts the text data into a numerical feature matrix that can be used to train the SVM model.\n",
        "\n",
        "The SVM model is trained using the SVC class from scikit-learn with a linear kernel and a regularization parameter of 1.0. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "E1Lu3HMamD6G"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/Dell/miniconda3/envs/idls23/lib/python3.8/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, kernel=&#x27;linear&#x27;, max_iter=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.1, kernel=&#x27;linear&#x27;, max_iter=5000)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(C=0.1, kernel='linear', max_iter=5000)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# train the SVM model\n",
        "svm = SVC(kernel='linear', C=0.1,max_iter=5000)\n",
        "svm.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfZSuH_Zr2F7"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "tnqFRmpdr52U"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM Model Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.83      0.65     39996\n",
            "           1       0.60      0.26      0.37     39981\n",
            "\n",
            "    accuracy                           0.55     79977\n",
            "   macro avg       0.57      0.55      0.51     79977\n",
            "weighted avg       0.57      0.55      0.51     79977\n",
            "\n",
            "SVM Accuracy : 54.54568188354152\n"
          ]
        }
      ],
      "source": [
        "# evaluate the SVM model on the testing set\n",
        "y_pred_svm = svm.predict(X_test_tfidf)\n",
        "print(\"SVM Model Report:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "svm_accuracy = 0\n",
        "ytest = y_test.values\n",
        "for i in range(len(y_pred_svm)):\n",
        "    if y_pred_svm[i]==ytest[i]:\n",
        "        svm_accuracy += 1\n",
        "svm_accuracy = (svm_accuracy/len(y_pred_svm))*100\n",
        "print(\"SVM Accuracy :\",svm_accuracy)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save and load SVM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save the model to models/\n",
        "filename = 'models/svm_model.sav'\n",
        "pickle.dump(svm, open(filename, 'wb'))\n",
        "\n",
        "# load the model from models/\n",
        "svm = pickle.load(open(filename, 'rb'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the model using LR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   24.3s finished\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.3, max_iter=1000, random_state=42, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.3, max_iter=1000, random_state=42, verbose=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=0.3, max_iter=1000, random_state=42, verbose=1)"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_model = LogisticRegression(C=0.3,max_iter=1000,random_state=42,verbose=1)\n",
        "lr_model.fit(X_train_tfidf, y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate the LR Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LR Model Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.75      0.77     39996\n",
            "           1       0.76      0.80      0.78     39981\n",
            "\n",
            "    accuracy                           0.78     79977\n",
            "   macro avg       0.78      0.78      0.78     79977\n",
            "weighted avg       0.78      0.78      0.78     79977\n",
            "\n",
            "LR Accuracy : 77.55604736361704\n"
          ]
        }
      ],
      "source": [
        "# evaluate the LR model on the testing set\n",
        "print(\"LR Model Report:\")\n",
        "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "lr_accuracy = 0\n",
        "ytest = y_test.values\n",
        "for i in range(len(y_pred_lr)):\n",
        "    if y_pred_lr[i]==ytest[i]:\n",
        "        lr_accuracy += 1\n",
        "lr_accuracy = (lr_accuracy/len(y_pred_lr))*100\n",
        "print(\"LR Accuracy :\",lr_accuracy)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save and load LR model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save the model to models/\n",
        "filename = 'models/lr_model.sav'\n",
        "pickle.dump(svm, open(filename, 'wb'))\n",
        "\n",
        "# load the model from models/\n",
        "lr_model = pickle.load(open(filename, 'rb'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train the model on Decision Tree "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=100, random_state=1)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=100, random_state=1)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt_model = DecisionTreeClassifier(criterion='entropy', random_state=1,max_depth=100)\n",
        "dt_model.fit(X_train_tfidf,y_train)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate DT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DT Model Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.71      0.70     39996\n",
            "           1       0.70      0.69      0.70     39981\n",
            "\n",
            "    accuracy                           0.70     79977\n",
            "   macro avg       0.70      0.70      0.70     79977\n",
            "weighted avg       0.70      0.70      0.70     79977\n",
            "\n",
            "DT Accuracy : 69.81007039523863\n"
          ]
        }
      ],
      "source": [
        "# evaluate the DT model on the testing set\n",
        "print(\"DT Model Report:\")\n",
        "y_pred_dt = dt_model.predict(X_test_tfidf)\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "dt_accuracy = 0\n",
        "ytest = y_test.values\n",
        "for i in range(len(y_pred_dt)):\n",
        "    if y_pred_dt[i]==ytest[i]:\n",
        "        dt_accuracy += 1\n",
        "dt_accuracy = (dt_accuracy/len(y_pred_dt))*100\n",
        "print(\"DT Accuracy :\",dt_accuracy)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save and load DT model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "#save the model to models/\n",
        "filename = 'models/dt_model.sav'\n",
        "pickle.dump(svm, open(filename, 'wb'))\n",
        "\n",
        "# load the model from models/\n",
        "dt_model = pickle.load(open(filename, 'rb'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get old tweets from Jan-Dec 2016"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Twitter seems to have updated their policy. Attempting to use an alternate approach.\n",
        "Cloning the github repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!git clone https://github.com/Altimis/Scweet.git"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the code below from the Scweet/Scweet directory in terminal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install -r Scweet/requirements.txt\n",
        "# !pip3 install -U selenium==4.2.0\n",
        "# !python scweet.py --words \"AAPL\" --until 2016-12-31 --since 2016-01-01 --limit 10 --interval 1 --display_type Latest --lang=\"en\" --headless False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_old_tweets(scraped_tweets_path):\n",
        "    #read the scraped tweets and timestamp from Scweet\n",
        "    old_tweets_df = pd.read_csv(scraped_tweets_path)\n",
        "    #rename columns to match train set\n",
        "    old_tweets_df.rename(columns={'Embedded_text':'tweet','Timestamp':'Date'},inplace=True)\n",
        "    old_tweets_df = old_tweets_df[['tweet','Date']]\n",
        "    #Drop duplicates\n",
        "    old_tweets_df.dropna(inplace=True)\n",
        "    #re-format time to yyyy-mm-dd format\n",
        "    old_tweets_df['Date'] = pd.to_datetime(old_tweets_df['Date'], format='%Y-%m-%d', errors='coerce')\n",
        "    old_tweets_df['Date'] = old_tweets_df['Date'].dt.strftime('%Y-%m-%d')\n",
        "    old_tweets_df = pd.DataFrame(data=old_tweets_df)\n",
        "    # #save the csv file\n",
        "    old_tweets_df.to_csv('old_tweets.csv')\n",
        "    #pre-process the old tweets dataframe and drop duplicates\n",
        "    old_tweets_preprocessed = process_tweet_dataframe(old_tweets_df)\n",
        "    old_tweets_preprocessed.drop_duplicates(inplace=True)\n",
        "    #save the pre-processed old tweets\n",
        "    old_tweets_preprocessed.to_csv('old_tweets_preprocessed.csv')\n",
        "    return old_tweets_preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Preprocessing complete.\n",
            "Time Taken: 0 seconds\n"
          ]
        }
      ],
      "source": [
        "old_tweets_preprocessed_df = get_old_tweets('Scweet/Scweet/outputs/AAPL_2016-01-01_2016-12-31.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load and check the old_tweets_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {},
      "outputs": [],
      "source": [
        "old_tweets_preprocessed_df = pd.read_csv('old_tweets_preprocessed.csv')\n",
        "old_tweets_preprocessed_df.drop(columns=['Unnamed: 0'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1846 entries, 0 to 1845\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Date    1846 non-null   object\n",
            " 1   tweet   1846 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 29.0+ KB\n"
          ]
        }
      ],
      "source": [
        "old_tweets_preprocessed_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>best apple inc headline 2015 apple nasdaq aapl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>trending tech stock aapl neon plug bbry fb URL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>iphone fitness apps help keep new year resolut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>aapl selling mill iphones india f16q1 mill f16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>trade stock holding gap URL USER stock trading...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>USER able make iphone read ebook outloud buyin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>rwm short russell 200 fund stock message board...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>replying USER</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>erbb stock forum updated saturday january 2016...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>aapl financials updated saturday january 2016 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>pphm recent news updated saturday january 2016...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>think aapl fine year mobbed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>make io default apps disappear URL appleinside...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>opinion updated saturday january 2016 45 47 pm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>USER tripchowdhury another dumb analyst talkin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>apple planning investment indonesia scale URL ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>shlx shell midstream partner lp message board ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>USER self interested push plan stock buyback a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>pipsfinder story apple inc aapl may move iphon...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>rt URL paper trading simulator learn trade lik...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Date                                              tweet\n",
              "0   2016-01-01  best apple inc headline 2015 apple nasdaq aapl...\n",
              "1   2016-01-01    trending tech stock aapl neon plug bbry fb URL \n",
              "2   2016-01-01  iphone fitness apps help keep new year resolut...\n",
              "3   2016-01-01    aapl selling mill iphones india f16q1 mill f16 \n",
              "4   2016-01-02  trade stock holding gap URL USER stock trading...\n",
              "5   2016-01-02  USER able make iphone read ebook outloud buyin...\n",
              "6   2016-01-02  rwm short russell 200 fund stock message board...\n",
              "7   2016-01-02                                     replying USER \n",
              "8   2016-01-02  erbb stock forum updated saturday january 2016...\n",
              "9   2016-01-02  aapl financials updated saturday january 2016 ...\n",
              "10  2016-01-02  pphm recent news updated saturday january 2016...\n",
              "11  2016-01-02                       think aapl fine year mobbed \n",
              "12  2016-01-02  make io default apps disappear URL appleinside...\n",
              "13  2016-01-02  opinion updated saturday january 2016 45 47 pm...\n",
              "14  2016-01-03  USER tripchowdhury another dumb analyst talkin...\n",
              "15  2016-01-03  apple planning investment indonesia scale URL ...\n",
              "16  2016-01-03  shlx shell midstream partner lp message board ...\n",
              "17  2016-01-03  USER self interested push plan stock buyback a...\n",
              "18  2016-01-03  pipsfinder story apple inc aapl may move iphon...\n",
              "19  2016-01-03  rt URL paper trading simulator learn trade lik..."
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(old_tweets_preprocessed_df.head(20))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Predict the sentiment using trained LR model on scraped old tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_old = old_tweets_preprocessed_df.tweet\n",
        "X_old_tfidf = tfidf.transform(X_old)\n",
        "y_pred_old = lr_model.predict(X_old_tfidf)\n",
        "old_tweets_preprocessed_df['sentiment'] = y_pred_old"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1846 entries, 0 to 1845\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Date       1846 non-null   object\n",
            " 1   tweet      1846 non-null   object\n",
            " 2   sentiment  1846 non-null   int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 43.4+ KB\n"
          ]
        }
      ],
      "source": [
        "old_tweets_preprocessed_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>tweet</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>best apple inc headline 2015 apple nasdaq aapl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>trending tech stock aapl neon plug bbry fb URL</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>iphone fitness apps help keep new year resolut...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>aapl selling mill iphones india f16q1 mill f16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>trade stock holding gap URL USER stock trading...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>USER able make iphone read ebook outloud buyin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>rwm short russell 200 fund stock message board...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>replying USER</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>erbb stock forum updated saturday january 2016...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>aapl financials updated saturday january 2016 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>pphm recent news updated saturday january 2016...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>think aapl fine year mobbed</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>make io default apps disappear URL appleinside...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>opinion updated saturday january 2016 45 47 pm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>USER tripchowdhury another dumb analyst talkin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>apple planning investment indonesia scale URL ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>shlx shell midstream partner lp message board ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>USER self interested push plan stock buyback a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>pipsfinder story apple inc aapl may move iphon...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>rt URL paper trading simulator learn trade lik...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Date                                              tweet  sentiment\n",
              "0   2016-01-01  best apple inc headline 2015 apple nasdaq aapl...          0\n",
              "1   2016-01-01    trending tech stock aapl neon plug bbry fb URL           0\n",
              "2   2016-01-01  iphone fitness apps help keep new year resolut...          0\n",
              "3   2016-01-01    aapl selling mill iphones india f16q1 mill f16           0\n",
              "4   2016-01-02  trade stock holding gap URL USER stock trading...          0\n",
              "5   2016-01-02  USER able make iphone read ebook outloud buyin...          1\n",
              "6   2016-01-02  rwm short russell 200 fund stock message board...          0\n",
              "7   2016-01-02                                     replying USER           1\n",
              "8   2016-01-02  erbb stock forum updated saturday january 2016...          0\n",
              "9   2016-01-02  aapl financials updated saturday january 2016 ...          0\n",
              "10  2016-01-02  pphm recent news updated saturday january 2016...          0\n",
              "11  2016-01-02                       think aapl fine year mobbed           0\n",
              "12  2016-01-02  make io default apps disappear URL appleinside...          0\n",
              "13  2016-01-02  opinion updated saturday january 2016 45 47 pm...          0\n",
              "14  2016-01-03  USER tripchowdhury another dumb analyst talkin...          0\n",
              "15  2016-01-03  apple planning investment indonesia scale URL ...          0\n",
              "16  2016-01-03  shlx shell midstream partner lp message board ...          0\n",
              "17  2016-01-03  USER self interested push plan stock buyback a...          0\n",
              "18  2016-01-03  pipsfinder story apple inc aapl may move iphon...          0\n",
              "19  2016-01-03  rt URL paper trading simulator learn trade lik...          0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(old_tweets_preprocessed_df.head(20))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Group by data and average sentiment values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {},
      "outputs": [],
      "source": [
        "old_tweets_avg = old_tweets_preprocessed_df.groupby(['Date']).aggregate(\n",
        "    {'sentiment': 'mean'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 364 entries, 2016-01-01 to 2016-12-30\n",
            "Data columns (total 1 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   sentiment  364 non-null    float64\n",
            "dtypes: float64(1)\n",
            "memory usage: 5.7+ KB\n"
          ]
        }
      ],
      "source": [
        "old_tweets_avg.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-01</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-02</th>\n",
              "      <td>0.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-03</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-05</th>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-06</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-07</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-08</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-09</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-10</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-11</th>\n",
              "      <td>0.100000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-12</th>\n",
              "      <td>0.111111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-13</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-14</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-15</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-16</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            sentiment\n",
              "Date                 \n",
              "2016-01-01   0.000000\n",
              "2016-01-02   0.200000\n",
              "2016-01-03   0.000000\n",
              "2016-01-05   0.100000\n",
              "2016-01-06   0.000000\n",
              "2016-01-07   0.000000\n",
              "2016-01-08   0.000000\n",
              "2016-01-09   0.000000\n",
              "2016-01-10   0.000000\n",
              "2016-01-11   0.100000\n",
              "2016-01-12   0.111111\n",
              "2016-01-13   0.000000\n",
              "2016-01-14   0.000000\n",
              "2016-01-15   0.000000\n",
              "2016-01-16   0.000000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(old_tweets_avg.head(15))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Save the average sentiment dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {},
      "outputs": [],
      "source": [
        "old_tweets_avg.to_csv('old_tweets_average.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Load the average sentiment dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-01</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-02</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-03</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  sentiment\n",
              "0  2016-01-01        0.0\n",
              "1  2016-01-02        0.2\n",
              "2  2016-01-03        0.0\n",
              "3  2016-01-05        0.1\n",
              "4  2016-01-06        0.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "old_tweets_avg = pd.read_csv('old_tweets_average.csv')\n",
        "display(old_tweets_avg.head())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Yahoo Finance data for AAPL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 308,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>PriceDiff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>-0.603296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>-0.459333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>-0.971218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>0.116545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-11</td>\n",
              "      <td>0.358786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  PriceDiff\n",
              "0  2016-01-05  -0.603296\n",
              "1  2016-01-06  -0.459333\n",
              "2  2016-01-07  -0.971218\n",
              "3  2016-01-08   0.116545\n",
              "4  2016-01-11   0.358786"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "aapl_price_diff = pd.read_csv('YahooFinance/AAPL_PriceDiff.csv')\n",
        "display(aapl_price_diff.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 314,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>PriceDiff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.603296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.459333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.971218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.116545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-11</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.358786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  sentiment  PriceDiff\n",
              "0  2016-01-05        0.1  -0.603296\n",
              "1  2016-01-06        0.0  -0.459333\n",
              "2  2016-01-07        0.0  -0.971218\n",
              "3  2016-01-08        0.0   0.116545\n",
              "4  2016-01-11        0.1   0.358786"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "stock_prediction_df = pd.merge(old_tweets_avg, aapl_price_diff, left_on='Date', right_on='Date', how='inner')\n",
        "display(stock_prediction_df.head())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save the stock_prediction dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 315,
      "metadata": {},
      "outputs": [],
      "source": [
        "stock_prediction_df.to_csv('stock_prediction.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load the stock_prediction dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 316,
      "metadata": {},
      "outputs": [],
      "source": [
        "stock_prediction_df = pd.read_csv('stock_prediction.csv')\n",
        "stock_prediction_df.drop(columns=['Unnamed: 0'],inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 317,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>PriceDiff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>0.1</td>\n",
              "      <td>-0.603296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.459333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.971218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.116545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-01-11</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.358786</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  sentiment  PriceDiff\n",
              "0  2016-01-05        0.1  -0.603296\n",
              "1  2016-01-06        0.0  -0.459333\n",
              "2  2016-01-07        0.0  -0.971218\n",
              "3  2016-01-08        0.0   0.116545\n",
              "4  2016-01-11        0.1   0.358786"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(stock_prediction_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "idls23",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "7c32006d7ee671581f0b03c98a5b552fc82b4869083f1d9b843962b3bbd55f94"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
